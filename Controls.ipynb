{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf30fa2-58ad-49d7-a39b-48bab1ab4ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02a9d7-6fc0-441c-b3aa-3f954bce2771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from the CSV file\n",
    "csv_path = '/Path/to/genomes.csv'\n",
    "genome_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Regular expression pattern to identify SSRs\n",
    "ssr_pattern = r'(\\w+?)\\1{4,50}'  # Pattern for SSRs with 4 to 50 repeats\n",
    "\n",
    "# Function to identify unique, minimal rotations of SSRs to standardize SSR matches\n",
    "def smallest_rotation(ssr):\n",
    "    return min(ssr[i:] + ssr[:i] for i in range(len(ssr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733ae63-e76b-4067-827d-60c1675c1752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process a chunk of sequence and find SSRs within it\n",
    "def process_chunk(sequence_chunk, start_pos, seen_positions):\n",
    "    chunk_ssrs = []  # List to store the unique SSRs found in this chunk of sequence\n",
    "    \n",
    "    # Use regular expression to find all possible SSRs in the current sequence chunk\n",
    "    for match in re.finditer(ssr_pattern, sequence_chunk):  \n",
    "        # Standardize the SSR by finding the smallest rotation (this makes it easier to compare SSRs)\n",
    "        ssr = smallest_rotation(match.group(0)) \n",
    "        \n",
    "        # Calculate the start position of the SSR in the entire genome\n",
    "        ssr_start = start_pos + match.start() \n",
    "        \n",
    "        # Calculate the end position of the SSR in the genome\n",
    "        ssr_end = ssr_start + len(ssr) - 1  # Subtract 1 to account for zero-based indexing\n",
    "        \n",
    "        # Check if this SSR is already present in the `seen_positions` list (to avoid overlaps)\n",
    "        # `seen_positions` stores the start and end positions of already encountered SSRs\n",
    "        if not any(start <= ssr_start <= end or start <= ssr_end <= end for start, end in seen_positions):\n",
    "            # If the SSR doesn't overlap with any previously seen SSRs, add it to the list\n",
    "            chunk_ssrs.append((ssr, ssr_start))  # Store the SSR and its start position in the chunk\n",
    "            seen_positions.append((ssr_start, ssr_end))  # Track the start and end positions of the found SSR\n",
    "\n",
    "    return chunk_ssrs  # Return the list of SSRs found in this chunk\n",
    "\n",
    "# Function to find SSRs using a sliding window approach on the genome sequence\n",
    "def sliding_window_ssr_finder(genome_sequence, chunk_size, step_size):\n",
    "    total_bases = len(genome_sequence)  # Get the total number of bases in the genome sequence\n",
    "    unique_ssrs = {}  # Dictionary to store unique SSRs and their positions\n",
    "    seen_positions = []  # List to keep track of start and end positions of already encountered SSRs\n",
    "\n",
    "    # Iterate over the genome using a sliding window approach (with specified chunk size and step size)\n",
    "    for start in tqdm(range(0, total_bases - chunk_size + 1, step_size), desc=\"Finding SSRs\"):\n",
    "        # Extract the current chunk of sequence based on the start position and chunk size\n",
    "        sequence_chunk = genome_sequence[start:start + chunk_size]\n",
    "        \n",
    "        # Process this chunk to find SSRs and get their positions\n",
    "        chunk_ssrs = process_chunk(sequence_chunk, start, seen_positions)\n",
    "\n",
    "        # Store the SSRs found in this chunk\n",
    "        for ssr, pos in chunk_ssrs:\n",
    "            if ssr not in unique_ssrs:\n",
    "                unique_ssrs[ssr] = pos  # Add the SSR and its position to the dictionary if it is not already there\n",
    "\n",
    "    return unique_ssrs  # Return the dictionary of unique SSRs and their positions\n",
    "\n",
    "# Parameters for SSR search\n",
    "chunk_size = 10000\n",
    "step_size = 100\n",
    "\n",
    "# List to hold the total SSR count for each iteration\n",
    "ssr_details_per_iteration = []\n",
    "\n",
    "# Combine all sequences into one large genome sequence\n",
    "genome_sequence = ''.join(genome_data['Sequence'])\n",
    "\n",
    "# Loop 100 times, shuffle the genome sequence, and collect SSR counts for each randomization\n",
    "for iteration in range(10):\n",
    "    print(f\"Iteration {iteration + 1}\")\n",
    "    \n",
    "    # Shuffle the genome sequence at the base level\n",
    "    shuffled_genome_sequence = ''.join(np.random.permutation(list(genome_sequence)))\n",
    "\n",
    "    # Extract unique SSRs from the shuffled genome\n",
    "    unique_ssrs = sliding_window_ssr_finder(shuffled_genome_sequence, chunk_size, step_size)\n",
    "    \n",
    "    # Count the SSRs found in this iteration and store the count\n",
    "    total_ssrs = len(unique_ssrs)\n",
    "    for ssr, pos in unique_ssrs.items():\n",
    "        ssr_details_per_iteration.append({'Iteration': iteration + 1, 'SSR': ssr, 'Position': pos})\n",
    "\n",
    "# Convert the list of SSR counts into a DataFrame\n",
    "ssr_counts_df = pd.DataFrame(ssr_details_per_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b610872-cec5-498f-83f5-a7c18a01d7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the output file where the SSR details will be saved\n",
    "output_file = 'output.txt'\n",
    "\n",
    "# Open the output file in write mode ('w')\n",
    "with open(output_file, 'w') as f:  \n",
    "    # Iterate through the list 'ssr_details_per_iteration' which contains SSR details for each iteration\n",
    "    for record in ssr_details_per_iteration:  \n",
    "        # Write each record's SSR details to the file in a readable format\n",
    "        # Format: \"Iteration: <iteration>, SSR: <SSR>, Position: <position>\"\n",
    "        f.write(f\"Iteration: {record['Iteration']}, SSR: {record['SSR']}, Position: {record['Position']}\\n\")  \n",
    "\n",
    "# Confirmation\n",
    "print(f\"SSR details for all iterations have been written to {output_file}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
